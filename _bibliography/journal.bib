---
---

@article{costes2020towards,
  title={Towards Haptic Images: a Survey on Touchscreen-Based Surface Haptics.},
  author={Costes, Antoine and Danieau, Fabien and Argelaguet, Ferran and Guillotel, Philippe and L{\'e}cuyer, Anatole},
  journal={IEEE Transactions on Haptics},
  year={2020},
  abstract = {The  development  of  tactile  screens  opens  new  per-spectives for co-located image and haptic rendering, leading to theconcept  of  “haptic  images”.  They  emerge  from  the  combinationof image data, rendering hardware, and haptic perception. Thisenables one to perceive haptic feedback while manually exploringan image. This raises nevertheless two scientific challenges, whichserve  as  thematic  axes  of  the  state  of  the  art  in  this  survey.Firstly,  the  choice  of  appropriate  haptic  data  raises  a  numberof   issues   about   human   perception,   measurements,   modelingand  distribution.  Secondly,  the  choice  of  appropriate  renderingtechnology  implies  a  difficult  trade-off  between  expressivenessand  usability.},
  pdf = {fdanieau.free.fr/pubs/ToH2020.pdf},
  doi = {10.1109/TOH.2020.2984754}
}


@article{costes2019touchy,
  title={Touchy: A visual approach for simulating haptic effects on touchscreens},
  author={Costes, Antoine and Argelaguet, Ferran and Danieau, Fabien and Guillotel, Philippe and L{\'e}cuyer, Anatole},
  journal={Frontiers in ICT},
  volume={6},
  pages={1},
  year={2019},
  publisher={Frontiers},
  doi = {10.3389/fict.2019.00001},
  abstract = {Haptic enhancement of touchscreens usually involves vibrating motors producing limited sensations or custom mechanical actuators that are difficult to disseminate. In this paper, we propose an alternative approach called “Touchy,” where a symbolic cursor is introduced under the user's finger, to evoke various haptic properties through changes in its shape and motion. This novel metaphor enables to address four different perceptual dimensions, namely: hardness, friction, fine roughness, and macro roughness. Our metaphor comes with a set of seven visual effects that we compared with real texture samples within a user study conducted with 14 participants. Taken together our results show that Touchy is able to elicit clear and distinct haptic properties: stiffness, roughness, reliefs, stickiness, and slipperiness.}
}

@article{danieau2014kinesthetic,
  title={A Kinesthetic Washout Filter for Force-Feedback Rendering},
  author={Danieau, Fabien and L{\'e}cuyer, Anatole and Guillotel, Philippe and Fleureau, Julien and Mollet, Nicolas and Christie, Marc},
  journal={IEEE transactions on haptics},
  volume={8},
  number={1},
  pages={114--118},
  year={2014},
  publisher={IEEE},
  doi = {10.1109/TOH.2014.2381652},
  abstract = {Today haptic feedback can be designed and associated to audiovisual content (haptic-audiovisuals or HAV). Although there are multiple means to create individual haptic effects, the issue of how to properly adapt such effects on force-feedback devices has not been addressed and is mostly a manual endeavor. We propose a new approach for the haptic rendering of HAV, based on a washout filter for force-feedback devices. A body model and an inverse kinematics algorithm simulate the user's kinesthetic perception. Then, the haptic rendering is adapted in order to handle transitions between haptic effects and to optimize the amplitude of effects regarding the device capabilities. Results of a user study show that this new haptic rendering can successfully improve the HAV experience.},
  pdf = {fdanieau.free.fr/pubs/washoutFilter.pdf}
}

@article{danieau2014toward,
  title={Toward haptic cinematography: enhancing movie experiences with camera-based haptic effects},
  author={Danieau, Fabien and Fleureau, Julien and Guillotel, Philippe and Mollet, Nicolas and Christie, Marc and L{\'e}cuyer, Anatole},
  journal={IEEE MultiMedia},
  volume={21},
  number={2},
  pages={11--21},
  year={2014},
  publisher={IEEE},
  doi = { 10.1109/MMUL.2013.64},
  abstract = {Haptics, the technology which brings tactile or force-feedback to users, has a great potential for enhancing movies and could lead to new immersive experiences. This article introduces haptic cinematography, which presents haptics as a new component of the filmmaker's toolkit. The authors propose a taxonomy of haptic effects and introduce new effects coupled with classical cinematographic motions to enhance the video-viewing experience. They propose two models to render haptic effects based on camera motions: the first model makes the audience feel the motion of the camera, and the second provides haptic metaphors related to the semantics of the camera effect. Results from a user study suggest that these new effects improve the quality of experience. Filmmakers can use this new way of creating haptic effects to propose new immersive audio-visual experiences.},
  pdf = {pdfhal.inria.fr/docs/00/91/80/74/PDF/IEEE_MM.pdf}
}


@article{danieau2012enhancing,
  title={Enhancing audiovisual experience with haptic feedback: a survey on HAV},
  author={Danieau, Fabien and L{\'e}cuyer, Anatole and Guillotel, Philippe and Fleureau, Julien and Mollet, Nicolas and Christie, Marc},
  journal={IEEE transactions on haptics},
  volume={6},
  number={2},
  pages={193--205},
  year={2012},
  publisher={IEEE},
  abstract = {Haptic technology has been widely employed in applications ranging from teleoperation and medical simulation to art and design, including entertainment, flight simulation, and virtual reality. Today there is a growing interest among researchers in integrating haptic feedback into audiovisual systems. A new medium emerges from this effort: haptic-audiovisual (HAV) content. This paper presents the techniques, formalisms, and key results pertinent to this medium. We first review the three main stages of the HAV workflow: the production, distribution, and rendering of haptic effects. We then highlight the pressing necessity for evaluation techniques in this context and discuss the key challenges in the field. By building on existing technologies and tackling the specific challenges of the enhancement of audiovisual experience with haptics, we believe the field presents exciting research perspectives whose financial and societal stakes are significant.},
  doi = { 10.1109/TOH.2012.70},
  pdf = {hal.inria.fr/docs/00/76/62/59/PDF/manuscript.pdf}
}

@article{rouanet2012impact,
  title={The impact of human--robot interfaces on the learning of visual objects},
  author={Rouanet, Pierre and Oudeyer, Pierre-Yves and Danieau, Fabien and Filliat, David},
  journal={IEEE Transactions on Robotics},
  volume={29},
  number={2},
  pages={525--541},
  year={2012},
  publisher={IEEE},
  abstract = {This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.},
  doi = {10.1109/TRO.2012.2228134},
  pdf = {hal.inria.fr/docs/00/75/82/41/PDF/tro-2010-v10.pdf}
}
