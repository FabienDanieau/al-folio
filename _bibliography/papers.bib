---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,}
}

@article{einstein1950meaning,
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{costes2020towards,
  title={Towards Haptic Images: a Survey on Touchscreen-Based Surface Haptics.},
  author={Costes, Antoine and Danieau, Fabien and Argelaguet, Ferran and Guillotel, Philippe and L{\'e}cuyer, Anatole},
  journal={IEEE Transactions on Haptics},
  year={2020},
  abstract = {The  development  of  tactile  screens  opens  new  per-spectives for co-located image and haptic rendering, leading to theconcept  of  “haptic  images”.  They  emerge  from  the  combinationof image data, rendering hardware, and haptic perception. Thisenables one to perceive haptic feedback while manually exploringan image. This raises nevertheless two scientific challenges, whichserve  as  thematic  axes  of  the  state  of  the  art  in  this  survey.Firstly,  the  choice  of  appropriate  haptic  data  raises  a  numberof   issues   about   human   perception,   measurements,   modelingand  distribution.  Secondly,  the  choice  of  appropriate  renderingtechnology  implies  a  difficult  trade-off  between  expressivenessand  usability.},
  url = {http://fdanieau.free.fr/pubs/ToH2020.pdf}
}


@article{costes2019touchy,
  title={Touchy: A visual approach for simulating haptic effects on touchscreens},
  author={Costes, Antoine and Argelaguet, Ferran and Danieau, Fabien and Guillotel, Philippe and L{\'e}cuyer, Anatole},
  journal={Frontiers in ICT},
  volume={6},
  pages={1},
  year={2019},
  publisher={Frontiers},
  doi = {10.3389/fict.2019.00001},
  abstract = {Haptic enhancement of touchscreens usually involves vibrating motors producing limited sensations or custom mechanical actuators that are difficult to disseminate. In this paper, we propose an alternative approach called “Touchy,” where a symbolic cursor is introduced under the user's finger, to evoke various haptic properties through changes in its shape and motion. This novel metaphor enables to address four different perceptual dimensions, namely: hardness, friction, fine roughness, and macro roughness. Our metaphor comes with a set of seven visual effects that we compared with real texture samples within a user study conducted with 14 participants. Taken together our results show that Touchy is able to elicit clear and distinct haptic properties: stiffness, roughness, reliefs, stickiness, and slipperiness.},
  html = {https://www.frontiersin.org/articles/10.3389/fict.2019.00001/full}
}

@phdthesis{danieau2014contribution,
  title={Contribution to the study of haptic feedback for improving the audiovisual experience},
  author={Danieau, Fabien},
  year={2014},
  school={Rennes 1},
  url = {http://tel.archives-ouvertes.fr/docs/00/95/10/94/PDF/TheseFabienDanieauFinal.pdf},
}


@inproceedings{danieau2019automatic,
  title={Automatic Generation and Stylization of 3D Facial Rigs},
  author={Danieau, Fabien and Gubins, IIja and Olivier, Nicolas and Dumas, Olivier and Denis, Bernard and Lopez, Thomas and Mollet, Nicolas and Frager, Brian and Avril, Quentin},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  pages={784--792},
  year={2019},
  organization={IEEE},
  doi = {10.1109/VR.2019.8798208},
  abstract = {In this paper, we present a fully automatic pipeline for generating and stylizing high geometric and textural quality facial rigs. They are automatically rigged with facial blendshapes for animation, and can be used across platforms for applications including virtual reality, augmented reality, remote collaboration, gaming and more. From a set of input facial photos, our approach is to be able to create a photorealistic, fully rigged character in less than seven minutes. The facial mesh reconstruction is based on state-of-the art photogrammetry approaches. Automatic landmarking coupled with ICP registration with regularization provide direct correspondence and registration from a given generic mesh to the acquired facial mesh. Then, using deformation transfer, existing blendshapes are transferred from the generic to the reconstructed facial mesh. The reconstructed face is then fit to the full body generic mesh. Extra geometry such as jaws, teeth and nostrils are retargeted and transferred to the character. An automatic iris color extraction algorithm is performed to colorize a separate eye texture, animated with dynamic UVs. Finally, an extra step applies a style to the photorealis-tic face to enable blending of personalized facial features into any other character. The user's face can then be adapted to any human or non-human generic mesh. A pilot user study was performed to evaluate the utility of our approach. Up to 65% of the participants were successfully able to discern the presence of one's unique facial features when the style was not too far from a humanoid shape.},
  url = {http://fdanieau.free.fr/pubs/ieeevr2019.pdf}
}


@inproceedings{danieau2018hfx,
  title={HFX studio: haptic editor for full-body immersive experiences},
  author={Danieau, Fabien and Guillotel, Philippe and Dumas, Olivier and Lopez, Thomas and Leroy, Bertrand and Mollet, Nicolas},
  booktitle={Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology},
  pages={1--9},
  year={2018},
  doi = {10.1145/3281505.3281518},
  abstract = {Current virtual reality systems enable users to explore virtual worlds, fully embodied in avatars. This new type of immersive experience requires specific authoring tools. The traditional ones used in the movie and the video games industries were modified to support immersive visual and audio content. However, few solutions exist to edit haptic content, especially when the whole user's body is involved. To tackle this issue we propose HFX Studio, a haptic editor based on haptic perceptual models. Three models of pressure, vibration and temperature were defined to allow the spatialization of haptic effects on the user's body. These effects can be designed directly on the body (egocentric approach), or specified as objects of the scene (allocentric approach). The perceptual models are also used to describe capabilities of haptic devices. This way the created content is generic, and haptic feedback is rendered on the available devices. The concept has been implemented with the Unity®game engine, a tool already used in VR production. A qualitative pilot user study was conducted to analyze the usability of our tool with expert users. Results shows that the edition of haptic feedback is intuitive for these users.},
  url = {http://fdanieau.free.fr/pubs/hapticEditor.pdf}
}


@inproceedings{costes2018kinestouch,
  title={KinesTouch: 3D Force-Feedback Rendering for Tactile Surfaces},
  author={Costes, Antoine and Danieau, Fabien and Argelaguet-Sanz, Ferran and L{\'e}cuyer, Anatole and Guillotel, Philippe},
  booktitle={International Conference on Virtual Reality and Augmented Reality},
  pages={97--116},
  year={2018},
  organization={Springer},
  abstract = {In this paper, we introduce the KinesTouch, a novel approach for tactile screen enhancement providing four types of haptic feedback with a single force-feedback device: compliance, friction, fine roughness, and shape. We present the design and implementation of a corresponding set of haptic effects as well as a proof-of-concept setup. Regarding friction in particular, we propose a novel effect based on large lateral motion that increases or diminishes the sliding velocity between the finger and the screen. A user study was conducted on this effect to confirm its ability to produce distinct sliding sensations. Visual cues were confirmed to influence sliding judgments, but further studies would help clarifying the role of tactile cues. Finally, we showcase several use cases illustrating the possibilities offered by the KinesTouch to enhance 2D and 3D interactions on tactile screens in various contexts.},
  doi = {doi.org/10.1007/978-3-030-01790-3_6},
  url = {http://people.irisa.fr/Antoine.Costes/assets/publications/kinestouch.pdf}
}


@inproceedings{callens2018tangible,
  title={A Tangible Surface for Digital Sculpting in Virtual Environments},
  author={Callens, Edouard and Danieau, Fabien and Costes, Antoine and Guillotel, Philippe},
  booktitle={International Conference on Human Haptic Sensing and Touch Enabled Computer Applications},
  pages={157--168},
  year={2018},
  organization={Springer},
  abstract = {With the growth of virtual reality setups, digital sculpting tools become more and more immersive. It is now possible to create a piece of art within a virtual environment, directly with the controllers. However, these devices do not allow to touch the virtual material as a sculptor would do. To tackle this issue we investigate in this paper the use of a tangible surface that could be used in virtual reality setups. We designed a low-cost prototype composed of two layers of sensors in order to measure a wide range of pressure. We also propose two mapping techniques to fit our device to a virtual 3D mesh to be sculpted. Participants of an informal test were asked to reproduce a pattern on three meshes: a plane, a sphere and a teapot. They succeeded in this task, showing the potential of our approach.},
  doi = {10.1007/978-3-319-93399-3_15},
  url = {http://fdanieau.free.fr/pubs/tangibleCreation.pdf}
}


@inproceedings{costes2018haptic,
  title={Haptic material: A holistic approach for haptic texture mapping},
  author={Costes, Antoine and Danieau, Fabien and Argelaguet, Ferran and L{\'e}cuyer, Anatole and Guillotel, Philippe},
  booktitle={International Conference on Human Haptic Sensing and Touch Enabled Computer Applications},
  pages={37--45},
  year={2018},
  organization={Springer},
  abstract = {In this paper, we propose a new format for haptic texture mapping which is not dependent on the haptic rendering setup hardware. Our “haptic material” format encodes ten elementary haptic features in dedicated maps, similarly to “materials” used in computer graphics. These ten different features enable the expression of compliance, surface geometry and friction attributes through vibratory, cutaneous and kinesthetic cues, as well as thermal rendering. The diversity of haptic data allows various hardware to share this single format, each of them selecting which features to render depending on its capabilities.},
  doi = {10.1007/978-3-319-93399-3_4},
  url = {http://fdanieau.free.fr/pubs/Eurohaptics_2018_HapticMaterial.pdf}
}


@inproceedings{danieau2017enabling,
  title={Enabling embodiment and interaction in omnidirectional videos},
  author={Danieau, Fabien and Lopez, Thomas and Mollet, Nicolas and Leroy, Bertrand and Dumas, Olivier and Vial, Jean-Francois},
  booktitle={2017 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={697--702},
  year={2017},
  organization={IEEE},
  doi = {10.1109/ICME.2017.8019388},
  abstract = {This paper investigates the role of the embodiment in an immersive video experience. A system allowing to play back omnidirectional videos enhanced with real-time 3D content is presented. It enables the user to be embodied in an avatar and to interact with 3D objects added to the video. A user study was conducted to understand the impact of this embodiment on the user experience. Four different avatars were compared (none, human, ghost and astronaut) as well as three levels of user control on the avatar, and also the possibility to interact with the content. Results show that being embodied has benefits on the user experience but requires the representation to be in line with the story and the avatar to be fully controllable. Indeed a misadapted embodiment may decrease the experience.},
  url = {http://fdanieau.free.fr/pubs/embodiment.pdf}
}


@inproceedings{danieau2017attention,
  title={Attention guidance for immersive video content in head-mounted displays},
  author={Danieau, Fabien and Guillo, Antoine and Dor{\'e}, Renaud},
  booktitle={2017 IEEE Virtual Reality (VR)},
  pages={205--206},
  year={2017},
  organization={IEEE},
  doi={10.1109/VR.2017.7892248},
  abstract={Immersive videos allow users to freely explore 4 π steradian scenes within head-mounted displays (HMD), leading to a strong feeling of immersion. However users may miss important elements of the narrative if not facing them. Hence, we propose four visual effects to guide the user's attention. After an informal pilot study, two of the most efficient effects were evaluated through a user study. Results show that our approach has potential but it remains challenging to implicitly drive the user's attention outside of the field of view.},
  url={http://fdanieau.free.fr/pubs/gazeincitement.pdf}
}

@article{danieau2014kinesthetic,
  title={A Kinesthetic Washout Filter for Force-Feedback Rendering},
  author={Danieau, Fabien and L{\'e}cuyer, Anatole and Guillotel, Philippe and Fleureau, Julien and Mollet, Nicolas and Christie, Marc},
  journal={IEEE transactions on haptics},
  volume={8},
  number={1},
  pages={114--118},
  year={2014},
  publisher={IEEE},
  doi = {10.1109/TOH.2014.2381652},
  abstract = {Today haptic feedback can be designed and associated to audiovisual content (haptic-audiovisuals or HAV). Although there are multiple means to create individual haptic effects, the issue of how to properly adapt such effects on force-feedback devices has not been addressed and is mostly a manual endeavor. We propose a new approach for the haptic rendering of HAV, based on a washout filter for force-feedback devices. A body model and an inverse kinematics algorithm simulate the user's kinesthetic perception. Then, the haptic rendering is adapted in order to handle transitions between haptic effects and to optimize the amplitude of effects regarding the device capabilities. Results of a user study show that this new haptic rendering can successfully improve the HAV experience.},
  url = {http://fdanieau.free.fr/pubs/washoutFilter.pdf}
}


@article{danieau2014toward,
  title={Toward haptic cinematography: enhancing movie experiences with camera-based haptic effects},
  author={Danieau, Fabien and Fleureau, Julien and Guillotel, Philippe and Mollet, Nicolas and Christie, Marc and L{\'e}cuyer, Anatole},
  journal={IEEE MultiMedia},
  volume={21},
  number={2},
  pages={11--21},
  year={2014},
  publisher={IEEE},
  doi = { 10.1109/MMUL.2013.64},
  abstract = {Haptics, the technology which brings tactile or force-feedback to users, has a great potential for enhancing movies and could lead to new immersive experiences. This article introduces haptic cinematography, which presents haptics as a new component of the filmmaker's toolkit. The authors propose a taxonomy of haptic effects and introduce new effects coupled with classical cinematographic motions to enhance the video-viewing experience. They propose two models to render haptic effects based on camera motions: the first model makes the audience feel the motion of the camera, and the second provides haptic metaphors related to the semantics of the camera effect. Results from a user study suggest that these new effects improve the quality of experience. Filmmakers can use this new way of creating haptic effects to propose new immersive audio-visual experiences.},
  url = {http://hal.inria.fr/docs/00/91/80/74/PDF/IEEE_MM.pdf}
}


@inproceedings{danieau2012hapseat,
  title={HapSeat: producing motion sensation with multiple force-feedback devices embedded in a seat},
  author={Danieau, Fabien and Fleureau, Julien and Guillotel, Philippe and Mollet, Nicolas and L{\'e}cuyer, Anatole and Christie, Marc},
  booktitle={Proceedings of the 18th ACM symposium on Virtual reality software and technology},
  pages={69--76},
  year={2012},
  doi={10.1145/2407336.2407350},
  url={https://hal.inria.fr/docs/00/76/62/58/PDF/100-danieau.pdf},
  abstract={We introduce a novel way of simulating sensations of motion which does not require an expensive and cumbersome motion platform. Multiple force-feedbacks are applied to the seated user's body to generate a sensation of motion experiencing passive navigation. A set of force-feedback devices such as mobile armrests or headrests are arranged around a seat so that they can apply forces to the user. We have dubbed this new approach HapSeat. A proof of concept has been designed which uses three low-cost force-feedback devices, and two control models have been implemented. Results from the first user study suggest that subjective sensations of motion are reliably generated using either model. Our results pave the way to a novel device to generate consumer motion effects based on our prototype.}
}

@inproceedings{fleureau2016texture,
  title={Texture rendering on a tactile surface using extended elastic images and example-based audio cues},
  author={Fleureau, Julien and Lefevre, Yoan and Danieau, Fabien and Guillotel, Philippe and Costes, Antoine},
  booktitle={International Conference on Human Haptic Sensing and Touch Enabled Computer Applications},
  pages={350--359},
  year={2016},
  organization={Springer},
  doi={10.1007/978-3-319-42321-0_32},
  url={http://fdanieau.free.fr/pubs/eurohaptics.pdf},
  abstract={A texture rendering system relying on pseudo-haptic and audio feedback is presented in this paper. While the user touches the texture displayed on a tactile screen, the associated image is deformed according to the contact area and the rubbing motion to simulate pressure. Additionally audio feedback is synthesized in real-time to simulate friction. A novel example-based scheme takes advantage of recorded audio samples of friction between actual textures and a finger at several speeds to synthesize the final output sound. This system can be implemented on any existing tactile screen without any extra mechanical device.}
}


@inproceedings{rouanet2011robotic,
  title={A robotic game to evaluate interfaces used to show and teach visual objects to a robot in real world condition},
  author={Rouanet, Pierre and Danieau, Fabien and Oudeyer, Pierre-Yves},
  booktitle={Proceedings of the 6th international conference on Human-robot interaction},
  pages={313--320},
  url={http://flowers.inria.fr/Rouanet-Danieau-Oudeyer-hri2011.pdf},
  year={2011},
  doi={10.1145/1957656.1957782},
  abstract={In this paper, we present a real world user study of 4 interfaces designed to teach new visual objects to a social robot. This study was designed as a robotic game in order to maintain the user's motivation during the whole experiment. Among the 4 interfaces 3 were based on mediator objects such as an iPhone, a Wiimote and a laser pointer. They also provided the users with different kind of feedback of what the robot is perceiving. The fourth interface was a gesture based interface with a Wizard-of-Oz recognition system added to compare our mediator interfaces with a more natural interaction. Here, we specially studied the impact the interfaces have on the quality of the learning examples and the usability. We showed that providing non-expert users with a feedback of what the robot is perceiving is needed if one is interested in robust interaction. In particular, the iPhone interface allowed non-expert users to provide better learning examples due to its whole visual feedback. Furthermore, we also studied the user's gaming experience and found that in spite of its lower usability, the gestures interface was stated as entertaining as the other interfaces and increases the user's feeling of cooperating with the robot. Thus, we argue that this kind of interface could be well-suited for robotic game.}
}

@article{danieau2012enhancing,
  title={Enhancing audiovisual experience with haptic feedback: a survey on HAV},
  author={Danieau, Fabien and L{\'e}cuyer, Anatole and Guillotel, Philippe and Fleureau, Julien and Mollet, Nicolas and Christie, Marc},
  journal={IEEE transactions on haptics},
  volume={6},
  number={2},
  pages={193--205},
  year={2012},
  publisher={IEEE},
  abstract = {Haptic technology has been widely employed in applications ranging from teleoperation and medical simulation to art and design, including entertainment, flight simulation, and virtual reality. Today there is a growing interest among researchers in integrating haptic feedback into audiovisual systems. A new medium emerges from this effort: haptic-audiovisual (HAV) content. This paper presents the techniques, formalisms, and key results pertinent to this medium. We first review the three main stages of the HAV workflow: the production, distribution, and rendering of haptic effects. We then highlight the pressing necessity for evaluation techniques in this context and discuss the key challenges in the field. By building on existing technologies and tackling the specific challenges of the enhancement of audiovisual experience with haptics, we believe the field presents exciting research perspectives whose financial and societal stakes are significant.},
  doi = { 10.1109/TOH.2012.70},
  url = {http://hal.inria.fr/docs/00/76/62/59/PDF/manuscript.pdf}
}


@inproceedings{danieau2012framework,
  title={Framework for enhancing video viewing experience with haptic effects of motion},
  author={Danieau, Fabien and Fleureau, Julien and Cabec, Audrey and Kerbiriou, Paul and Guillotel, Philippe and Mollet, Nicolas and Christie, Marc and L{\'e}cuyer, Anatole},
  booktitle={2012 IEEE Haptics Symposium (HAPTICS)},
  pages={541--546},
  year={2012},
  url={http://hal.inria.fr/docs/00/76/62/57/PDF/Danieau2012-_A_framework_for_enhancing_video_viewing_experience_with_haptic_effects_of_motion.pdf},
  organization={IEEE},
  doi={10.1109/HAPTIC.2012.6183844},
  abstract={This work aims at enhancing a classical video viewing experience by introducing realistic haptic feelings in a consumer environment. More precisely, a complete framework to both produce and render the motion embedded in an audiovisual content is proposed to enhance a natural movie viewing session. We especially consider the case of a first-person point of view audiovisual content and we propose a general workflow to address this problem. This latter includes a novel approach to both capture the motion and video of the scene of interest, together with a haptic rendering system for generating a sensation of motion. A complete methodology to evaluate the relevance of our framework is finally proposed and demonstrates the interest of our approach.}
}

@article{rouanet2012impact,
  title={The impact of human--robot interfaces on the learning of visual objects},
  author={Rouanet, Pierre and Oudeyer, Pierre-Yves and Danieau, Fabien and Filliat, David},
  journal={IEEE Transactions on Robotics},
  volume={29},
  number={2},
  pages={525--541},
  year={2012},
  publisher={IEEE},
  abstract = {This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.},
  doi = {10.1109/TRO.2012.2228134},
  url = {http://hal.inria.fr/docs/00/75/82/41/PDF/tro-2010-v10.pdf}
}
