---
---

@inproceedings{lopez2017playback,
  title={A playback tool for reviewing VR experiences},
  author={Lopez, Thomas and Dumas, Olivier and Danieau, Fabien and Leroy, Bertrand and Mollet, Nicolas and Vial, Jean-Fran{\c{c}}ois},
  booktitle={Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology},
  pages={1--2},
  year={2017},
  doi = {10.1145/3139131.3141776},
  abstract = {Designing a VR content is a challenging task due to the complexity of the analysis of a user's experience. We propose a tool allowing a reviewer to record a user's movements when consuming a VR content, and to playback this experience. During the playback, the reviewer can visualize in real-time the visible objects to the user (within the field of view) or the interactive ones (within the workspace). Besides, the field of view and workspace of numerous devices can be simulated in order to predict how the content would fit. In the demonstration, a user is first invited to experience a VR scene. Then the recorded experience can be played back from a reviewer's point of view.},
  pdf = {fdanieau.free.fr/pubs/vrst2017.pdf}
}

@inproceedings{guillotel2016introducing,
  title={Introducing Basic Principles of Haptic Cinematography and Editing.},
  author={Guillotel, Philippe and Danieau, Fabien and Fleureau, Julien and Rouxel, Ines and Christie, M and Galvane, Q and Jhala, A and Ronfard, R},
  booktitle={WICED},
  pages={15--21},
  year={2016},
  pdf = {fdanieau.free.fr/pubs/WICED.pdf},
  abstract = {Adding the sense of touch to hearing and seeing would be necessary for a true immersive experience. This is the promise of the growing "4D-cinema" based on motion platforms and others sensory effects (water spray, wind, scent, etc.). Touch provides a new dimension for filmmakers and leads to a new creative area, the haptic cinematography. However design rules are required to use this sensorial modality in the right way for increasing the user experience. This paper addresses this issue, by introducing principles of haptic cinematography editing. The proposed elements are based on early feedback from different creative works performed by the authors (including a student in cinema arts), anticipating the role of haptographers, the experts on haptic content creation. Three full short movies have been augmented with haptic feedback and tested by numerous users, in order to provide the inputs for this introductory paper.},
  doi = {10.2312/wiced.20161096}
}

@inproceedings{danieau2016haptic,
  title={Haptic cinematography: Authoring haptic feedback for movies.},
  author={Danieau, Fabien},
  booktitle={Haptics Symposium Workshop on Creative Haptic Expression: Trends and Tools},
  year={2016},
  pdf = {2016.hapticssymposium.org/sites/files/HAPTIC2016_CreativeHapticExpression_Danieau.pdf}
}

@inproceedings{du2016visualizing,
  title={Visualizing the emotional journey of a museum},
  author={Du, Shen and Shu, Edouard and Tong, Feifei and Ge, Yinghao and Li, Lu and Qiu, Jingbo and Guillotel, Philippe and Fleureau, Julien and Danieau, Fabien and Muller, Daniel},
  booktitle={Proceedings of EmoVis 2016, ACM IUI 2016 Workshop on Emotion and Visualization, Sonoma, CA, USA, March 10, 2016},
  number={103},
  pages={7--14},
  year={2016},
  organization={Link{\"o}ping University Electronic Press},
  pdf = {www.ep.liu.se/ecp/103/002/ecp16103002.pdf},
  doi = {10.3384/ecp10302},
  abstract = {Wearable devices and new types of sensors make it possible to capture people behavior, activity and, potentially, cognitive state in their daily life. Today those devices are mainly used for well-being applications, by recording and displaying peopleâ€™s activity. Some work have been published going a step further by inferring from the recorded signals the emotional state of individuals or group of people. However, the information provided and the way it is presented are still in their infancy, with time lined graphs showing calories, heart-rate, steps, temperature, and sometimes affective intensity.
In this paper we present an experiment done during the visit of different people in a museum of arts to capture the emotional impact of the exposed paintings. We also propose an associated visualization of their emotional journey. The emotion is here measured as the affective response to the paintings observation, and the processing algorithm is based on an existing technique adapted to the particular case of different observation durations. The visualization is based on a 3D map of the museum with different colors associated to the different paintings to get the emotional heat-map of the museum (more precisely the arousal dimension). The validation has been done in the museum of arts at Lyon, France, with 46 visitors, for a total of 27 paintings, exposed in three different rooms.}
}

@inproceedings{danieau2013h,
  title={H-Studio: an authoring tool for adding haptic and motion effects to audiovisual content},
  author={Danieau, Fabien and Bernon, J{\'e}r{\'e}mie and Fleureau, Julien and Guillotel, Philippe and Mollet, Nicolas and Christie, Marc and L{\'e}cuyer, Anatole},
  booktitle={Proceedings of the adjunct publication of the 26th annual ACM symposium on User interface software and technology},
  pages={83--84},
  year={2013},
  doi = {10.1145/2508468.2514721},
  abstract = {Haptic and motion effects have been widely used for virtual reality applications in order to provide a physical feedback from the virtual world. Such feedback was recently studied to improve the user experience in audiovisual entertainment applications. But the creation of haptic and motion effects is a main issue and requires dedicated editing tool. This paper describes a user-friendly authoring tool to create and synchronize such effects with audiovisual content. More precisely we focus on the edition of motion effects. Authoring is simplified thanks to a dedicated graphical user interface, allowing either to import external data or to synthesize effects thanks to a force-feedback device. Another key feature of this editor is the playback function which enables to preview the motion effect. Hence this new tool allows non expert users to create immersive haptic-audiovisual experiences.}
}

@incollection{danieau2013hapseat2,
  title={HapSeat: a novel approach to simulate motion in audiovisual experiences},
  author={Danieau, Fabien and Fleureau, Julien and Guillotel, Philippe and Mollet, Nicolas and Christie, Marc and L{\'e}cuyer, Anatole},
  booktitle={ACM SIGGRAPH 2013 Emerging Technologies},
  pages={1--1},
  year={2013},
  doi = {10.1145/2503368.2503374},
  abstract = {The HapSeat is a novel and inexpensive approach for simulating motion sensations in audiovisual experience. Multiple force-feedbacks are applied to the sitting users' body to generate a 6DoF sensation of motion as users are experiencing passive navigation. A set of force-feedback devices (a headrest and mobile armrests) are arranged around a seat so that they can apply forces to the user. Several video sequences highlight the capabilities of the HapSeat. We propose SIGGRAPH attendees to experience these videos enhanced by haptic effects of motion.}
}

@incollection{danieau2013hapseat,
  title={HapSeat: a novel approach to simulate motion in a consumer environment},
  author={Danieau, Fabien and Fleureau, Julien and Guillotel, Philippe and Mollet, Nicolas and Christie, Marc and L{\'e}cuyer, Anatole},
  booktitle={CHI'13 Extended Abstracts on Human Factors in Computing Systems},
  pages={3035--3038},
  year={2013},
  doi = {10.1145/2468356.2479604},
  abstract = {The HapSeat is a novel approach for simulating motion sensations in a consumer environment. Multiple force-feedbacks are applied to the seated user's body to generate a 6DoF sensation of motion while experiencing passive navigation. A set of force-feedback devices such as mobile armrests or headrests are arranged around a seat so that they can apply forces to the user. Several video sequences have been created to highlight the capabilities of the HapSeat. We propose to CHI attendees to experience these videos enhanced by haptic effects of motion.}
}
